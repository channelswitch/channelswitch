\documentclass[
	utf8,
	largesmallcaps,
	intlimits,
	widermath,
	sharecounter,
	nobreak,
	definition=marks,
	numbers,
	noparts
]{rtthesis}
\usepackage{etex}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{listings}
\usepackage{pgfplots}
\usepackage{xspace}

\setupThesis{
	author={Roland Stenholm},
	swetitle={En Tidsmultiplexad Kanalswitch för Dynamisk 
		Frekvensbandsreallokering},
	swesubtitle={},
	title={A Time-Multiplexed Channel Switch for Dynamic Frequency Band
		Reallocation},
	subtitle={},
	year=\the\year,
	type=msc,
	subject={Computer Engineering},
	division={Division of Computer Engineering},
	department=isy,
	examiner={Kent Palmkvist \AT \textsc{isy}, Linköpings universitet},
	supervisor={Oscar Gustafsson \AT \textsc{isy}, Linköpings universitet},
	keywords={parallel, interleaver, bitonic, sorter, clos, network, sts,
		switch, dfbr, dynamic, frequency, band, reallocation},
	isrn=LiTH-ISY-EX-{}-YY/NNNN-{}-SE,
	url={http://urn.kb.se/resolve?urn=urn:nbn:se:liu:diva-XXXXX},
	dedication={}
}
\AtBeginDocument{
	\bibliographystyle{plainnat}
}

\graphicspath{{fig/}}

\pgfplotsset{
	discard if not/.style 2 args={
		x filter/.code={
			\edef\tempa{\thisrow{#1}}
			\edef\tempb{#2}
			\ifx\tempa\tempb
			\else
				\def\pgfmathresult{inf}
			\fi
		}
	}
}

\newcommand{\figureref}[1]{\hyperref[#1]{figure~\ref*{#1}}}
\newcommand{\Figureref}[1]{\hyperref[#1]{Figure~\ref*{#1}}}
\newcommand{\Hypref}[1]{\hyperref[#1]{\ref*{#1}}}
\let\textabbr\textsc
\newcommand{\abbrFPGA}{\texorpdfstring{\textabbr{fpga}}{FPGA}\xspace}
\newcommand{\abbrDFBR}{\texorpdfstring{\textabbr{dfbr}}{DFBR}\xspace}
\newcommand{\homepage}{\url{https://github.com/channelswitch/channelswitch}}

\begin{document}

\selectlanguage{english}

\frontmatter
\maketitle

\begin{abstract}[swedish]
En delvis parallel och delvis seriell kanalswitch för användning inom \abbrDFBR
skapas. Dess permutation kan ändras medan den kör utan avbrott i dataströmmen.
Tre alternativ undersöks: ett baserat ett sorteringsnätverk, ett baserat på
minnen och multiplexrar och ett som baseras på Clos-nätverk. Versioner med
mönsterdata sparad i skiftregister och i minnen prövas. De implementeras i
automatiskt genererad Verilog och synthesiseras för en \abbrFPGA. Deras kostnad
i areaanvändning, minnesanvändning och maximal klockfrekvens jämförs.
Resultaten visar i princip att Clos-nätverken är bäst i alla avseenden och att
mönsterdata ska sparas i RAM-minnen och inte i skiftregister. Arbetet är open
source och kan laddas ner från \homepage.
\end{abstract}

\begin{abstract}[english]
A partially parallel reconfigurable channel switch is constructed for use in
\abbrDFBR. Its permutation can be changed while running without any
interruption in the streams of data. Three approaches are tried: one based on a
sorting network, one based on memories and multiplexers and one based on an
Clos network.  Variants with the pattern stored in memories and in shift
registers are tried.  They are implemented in automatically generated Verilog
and synthesized for an \abbrFPGA. Their cost in terms of area use, memory use
and maximum clock frequency is compared and the results show that the Clos
based approach is superior in all aspects and that pattern data should not be
saved in shift registers. The work is open source and available for download at
\homepage.
\end{abstract}

\begin{acknowledgments}
I would like to thank my family for being supportive and my advisor for all of his help during these last few months.
	\addvspace{1em}
	\begin{flushright}
		\textit{%
			Linköping, \date{\today}\\
			Roland Stenholm%
		}
	\end{flushright}
\end{acknowledgments}

\tableofcontents

\begin{notation}
	\centering

	\begin{notationtabular}{Abbreviations}{Abbreviation}{Meaning}
		\abbrFPGA\index{FPGA@\abbrFPGA!abbreviation} & Field
Programmable Gate Array \\
		\abbrDFBR\index{DFBR@\abbrDFBR!abbreviation} & Dynamic
Frequency Band Reallocation \\
	\end{notationtabular}
\end{notation}

\mainmatter

\chapter{Introduction}

\section{Motivation}

This work explores the problem of partially parallel reordering of streams of
data in digital electronics. Samples arrive in frames. Each sample in a frame
corresponds to one channel. The interleaver reorders the samples within a frame
arbitrarily, creating a new frame of the same size. The permutation of streams
is defined by the user and can be changed while the hardware is running. Each
sample in the input will appear exactly once in the output but there are no
limitations on the order in which they appear.

The hardware runs at a higher clock frequency than the samples of each stream
arrive. There are many clock cycles between one frame and the next. There are
not as many as there are samples in a frame, however. If there had been, the
problem could have been solved simply by writing samples into a RAM and then
reading them in the user-specified order. Instead, the hardware takes a few
samples per clock cycle as input over a period of a few hundred clock cycles.
How to accomplish this in an efficient manner is less obvious, and is the topic
of this report.

The interleaver must be able to operate continuously. For example, there shall
not be any clock cycles between frames where the interleaver does not take
inputs. The interleaver must also support switching of permutations without
pausing, but the time it takes is not important. There are no requirements on
latency either. It will be at least the same time it takes to input a frame a
frame, as a delay shorter than that would be impossible if the permutation
requires that a sample in the last clock cycle be output in the first.

The exact number of parallel inputs that are needed will depend on the clock
frequency that the chip will run at. The maximum clock frequency is limited to
the lowest of the maximum frequency set by any part of the chip. This can be
either the interleaver or by another part of the hardware such as the FFTs. The
implementor must choose a parameters that minimize the cost of the chip while
still having the required throughput. For this to be possible, the maximum
clock frequency of the chip as a function of its parameters must be known.

To find out the maximum clock frequency of the chip, the maximum frequency of
all of its components must be known. Therefore, a model for the limit to
maximum clock frequency imposed on the chip by the interleaver, depending on
its parameters, must be developed. This will be done by synthesizing
interleavers with different parameters and saving their timing information.

\section{Purpose}

\abbrDFBR is the practice of changing the frequency bands used by signals in
commuication hardware dynamically in response to demand. A \abbrDFBR capable
satellite can have many input signals, each with its own bandwidth depending on
the standard it uses. The signals will then be output at potentially different
frequency bands chosen by the operator or automatically by the hardware, in the
case of Cognitive Radio. \abbrDFBR also finds applications in digital TV
distribution in cable networks.

In broad terms, \abbrDFBR works by splitting its full bandwidth into many
smaller bands. Their bandwidth is chosen so that all expected input signals
will occupy roughly an integer multiple of these bands. The input signal is
split into its components using IFFTs or filters or something. The samples from
each band are rearranged. This is the function performed by the Channel Switch.
They are then reassembled into the output signal. This can be done in such a
way that signals which occupy more than one small band will not lose
information. The theory behind it is described in
\cite{Eghbali:2011:DFR:1960868.1960874}.

Another reason that a satellite may have many input or output streams is the
use of high-gain spot beam antennas. These only transmit or receive on one
direction. A satellite can use many such antennas, with each one covering a
smaller area of the earth. That way the satellite can distinguish signals in
the same frequency band if the transmitters are located in different beams and
can send signals only to receivers in specific areas. This means that each
antenna has its own signal and in combination with \abbrDFBR, a very large
number of channels need to be switched.

\section{Background}

The naive approach to the problem is to write the samples into a big RAM and
then read them out in random order. If $n$ samples arrive each clock cycle,
then an $n$-port RAM is required. Any more than two ports is impractical. With
one RAM per input, there would be enough bandwidth for all of the data, but
more logic is required to put each sample into the right memory.  It is far
from obvious how to make this work. To get a better understanding of the
problem, other solutions will be examined.

Sorting networks consist of compare-and swap elements as shown in
\figureref{fig:sortnetwork}. Data arrives at the left, and wherever two lines
are connected the values are swapped so that the larger one appears at the top.
A sorting network can perform the task of rearranging its inputs in any
arbitrary order. If a sorting network could be split across several clock
cycles then it could be used to solve this problem. Unlike in a sorting network
there is no need to actually perform comparisons every clock cycle, which could
lead to simplifications.

Clos networks are used in telephone switching. A Clos network is a construct
that creates the equivalent of a crossbar switch of a certain size using only
smaller crossbar switches. They were first described by Charles Clos in 1952
\cite{clos}. Clos networks are not time-multiplexed, but there is a construct
called a TST switch
%TODO Can't find a paper on TST. Only a couple of textbooks. Cite?
which is. Clos networks can also be made recursively to decrease complexity
even more. These are called Benes networks.

Digital communication protocols such as Wifi use something called interleaving.
Samples or bits of data are reordered within a frame before they are sent onto
the physical link, and at the receiver they are reordered back again. The
reason for this is that redundant codes are used for error correction. These
codes don't work well when an error affects several consecutive bits, but
that's the form real world errors usually take. The problem of interleaving is
especially interesting because a lot has been written specifically about
parallel interleaving, and things like clock cycles and power use are actually
discussed.

\section{Questions}

Can sorting networks be adapted to this problem? How about clos networks? What
is the cost of these approaches in terms of area and maximum frequency when
implemented on an \abbrFPGA?

\section{Not Considered}

This work concerns cases where the number of parallel inputs is much smaller
than the total number of samples in a frame. ASIC implementations are not
attempted due to the lack of a memory compiler. Latency is assumed to not be a
problem.

\chapter{Implementation}

\section{Code Generation}

The project takes the form of a command line program that generates C and
Verilog files for an interleaver depending on its arguments. One argument,
\lstinline{--type}, selects which type of interleaver to create. There are six because the
three approaches were implemented in two different ways each. The argument
\lstinline{--inputs} selects the number of parallel inputs.
\lstinline{--period} selects the number of clock cycles in a period. The number
given to \lstinline{--data} will be the width of each sample in bits. Only
powers of two can be used for \lstinline{--inputs} and \lstinline{--period} if
the type is based on a bitonic sorting network.

The command creates five files: \lstinline{switch.v} is the interleaver in
Verilog. The C file \lstinline{generate_pattern_data.c} and its header contain
the C code to realize a particular permutation. The output will then be sent to
the hardware's pattern\_data input. The testbench is in \lstinline{testbench.v}
and it needs \lstinline{vpi.c} so that it can call
\lstinline[language=C]{generate_pattern_data()}. See your simulator's manual
for how to use VPI.

The code has to be generated by a program because of limitations in Verilog
2001. There is a variable number of inputs and outputs. The obvious way to
implement this would be to use two-dimensional arrays with he number bits in a
sample in the packed dimension and the number of inputs in the unpacked
dimension. Unfortunately, Verilog 2001 doesn't support multidimensional ports,
so several input and output ports are created instead.

An attempt to create an implementation that used functions and for loops
instead of code generation ran into several other problems. Recursive functions
are difficult, because their arguments are static by default. This was overcome
but even though the code could eventually be simulated, it could not be
synthesized. The synthesizer was unable to figure out some static function calls
within loops and while it ran in the simulator, it was slower than the generated
code versions.

The code was generated using \lstinline{printf()}. Long strings are written
into their own files. The makefile used to build the project uses the shell's
\lstinline[language=sh]{printf} command to null-terminate the file, and it is
then turned into an object file using \lstinline[language=sh]{ld -b binary}.
The format string used to create the module specification may look like this:

\begin{lstlisting}[language=Verilog]
module switch(
  clk,
  reset,
  pattern_ready,
  pattern_valid,
  pattern_data,
  in_ready,
  in_valid,
  out_ready,
  out_valid,
  out_t%1$s
);
\end{lstlisting}

The \%1\$s is a printf positional parameter. It will be replaced with
a generated string with the input and output ports. This is because the number
of input and output ports depends on the arguments given to the program, as
previously described. Most of the program is written in this way. Anyone doing
similar things is encouraged to look at the GNU libc function
\lstinline[language=C]{open_memstream()}.

\section{Hardware Interface}

For handshaking, the hardware uses ready and valid signals. When ready is
asserted, that means that the corresponding input can be sent data next clock
cycle. When valid is asserted, it means that the data is valid. The user of the
hardware starts by asserting out\_ready. The interleaver will eventually assert
in\_ready. At that time, the user can begin to send data, which is done by
putting the samples in in0 to in$n$ and asserting in\_valid. The interleaved
stream will be sent to out0 to out$n$, and out\_valid will be asserted every
time new data is available. If the user can keep both out\_ready and in\_valid
high without interruption then the interleaver is capable of operating
continuously.

To change the permutation, the pattern inputs are used. The pattern\_ready and
pattern\_valid inputs work as usual. The data is send to pattern\_data, which
is eight bits wide regardless of the type of interleaver or its parameters. The
data shall be the output of the \lstinline[language=C]{generate_pattern_data()}
function.

Some versions of the interleaver require a pattern to be programmed into it
before they will start interleaving. Those that don't will initially perform
the null permutation, where the output is the same as the input.

When the user sends the hardware a pattern, the interleaver should deassert
pattern\_ready during the same clock cycle that the last pattern\_valid is
high. This is impossible to do purely with
\lstinline[language=Verilog]{always @(posedge clk)},
as whether pattern\_valid actually will be high cannot be known before that
very clock cycle. An \lstinline[language=Verilog]{assign} statement of some
sort would be required for it to behave correctly. This could be a surprise to
the user and affect the critical path.

In fact, the pattern\_ready signal will not be deasserted until one clock cycle
too late. It therefore does not quite follow specification. The data path
solves the same problem by using a buffer at the output and does follow spec.
The problem may be better solved, however, by instead signalling the user that
an attempt to send data failed because the device was full. This has not been
done.

\section{Testbench}

The generated code comes with a testbench. This testbench tests the hardware by
sending it random inputs. At random times, but not before verifying that the
current permutation is performed correctly, the testbench randomly generates a
new permutation. The function \lstinline[language=C]{generate_pattern_data()}
is called with that permutation as an argument, and the output of that function
is sent to the interleaver. A few tens of patterns are usually tried before the
testbench exits.

For the first half of the run, the testbench sets out\_ready and in\_valid
randomly during each clock cycle, to test that handshaking works correctly. In
the second half, a continuous run is tried. On average around 40 patterns will
be tried.

\chapter{Parallel Memories}

The first implementation is based around memories. Each output is given a
memory. Each incoming sample is written into the memory of the output it is
going to. Memories are written in sequential order and read out in random
order.

The problem occurs when multiple incoming samples from the same clock cycle are
going to the same output but in different clock cycles. Then, multiple samples
must be written to one memory. The parallel memories implementation solves this
by simply splitting each memory into several smaller ones. As many as there are
inputs. This lets multiple samples be written in one clock cycle. The total
memory size remains the same, however.

To enable continuous operation, there are two memory banks. When one is being
written to, the other is being read. The control word stores the read address
for each output, one bit for each of the $inputs^2$ memories telling us if it
is to be written to this clock cycle and if so, from which input.

In the initial version of this implementation the control word was stored in
two shift registers. This turned out to be bad in terms of chip area and
synthesis time. The second version uses two RAM memories. Two are needed so
that a new pattern can be used without interrupting the data stream.

\chapter{Bitonic Sorter}

\section{Theory}

\begin{wrapfigure}{R}{.4\textwidth}
\begin{center}
\includegraphics[width=.4\textwidth]{sorting_network.eps}
\end{center}
\caption{
A sorting network with 4 inputs.
}
\label{fig:sortnetwork}
\end{wrapfigure}

A sorting network is a construct that sorts its inputs. It is constructed from
compare and swap elements. Each one compares its two inpts and swaps them,
depending on the result of the comparison.

\Figureref{fig:sortnetwork} shows a small sorting network. Inputs arrive
from the left, and come out sorted on the right. Each arrow represents a
compare and swap element between the two points that it connects. The smaller
value goes in the direction of the arrow and the larger value in the other
direction. In the sorting network from the figure, no matter which numbers are
input, the output will always be sorted.

A sorting network therefore has the ability to reorder its inputs arbitrarily.
If a sorting network could be efficiently modified to work over several clock
cycles then it could be used for arbitrary interleaving.

\section{Implementation}

\begin{wrapfigure}{R}{.7\textwidth}
\begin{center}
\includegraphics[width=.7\textwidth]{sorting_network_2.eps}
\end{center}
\caption{
A bitonic sorting network with 8 inputs and how it might be converted to serial
operation.
}
\label{fig:bitonic}
\end{wrapfigure}

\Figureref{fig:bitonic} shows how this might be accomplished. It is based on
the bitonic sorting network. A bitonic sorter can be called the sorting network
equivalent of the merge sort algorithm. At the stage labeled A, the data
consists of 4 sorted lists, each with 2 samples. At B, it consists of 2 sorted
lists with 4 samples each. At C, the whole list is sorted. The bitonic sorter
thus merges smaller sorted lists into larger ones until the while input has
been sorted. This version of the bitonic sorting network will have its lists in
alternatingly ascending and descending order.

The exact details of how to build a bitonic sorter will not be described here,
but the key insights that allow the bitonic sorting network to be easily
serialized are as follows: The length of each arrow is a power of two, and that
all arrows with a length of $n$ are repeated for every multiple of $2n$ wires
(so if an arrow connects wires 0 and 2, another will connect 4 and 6, for
example).

Now, say we want to modify a bitonic sorting network with 8 inputs so that is
runs over two clock cycles, and takes 4 inputs each clock cycle. A dotted line
has been drawn through the middle of \figureref{fig:bitonic}. The upper half
is executed during the first clock cycle and the lower half would be executed
during the second. Arrows with a length of 2 or less are duplicated across both
clock cycles but only need to be implemented once, saving resources. Sometimes
they want to sort in different directions, but this is taken into account when
preparing patterns.

Consider the four arrows that are 4 wires long. They may need to swap a value
that arrives in the first clock cycle with one that arrives the next.
Obviously, this cannot be done without waiting for the next value to arrive.
These swappers are thus implemented using memories. During the first clock
cycle, they save the incoming data in the memory. During the second, they
output the incoming data immediately and let the previously stored value remain
in memory if they are supposed to swap the two values. If not, they output the
previously saved value while saving the incoming data. During the last clock
cycle, they write the value that was left in the memory.

Because all arrows in a bitonic sorter have lengths that are powers of two, any
arrow longer than the number of parallel inputs (which must be a power of two),
only connects to itself during different clock cycles. Their serialized
realizations therefore only occupy one wire.

The bitonic sorter has been implemented in automatically generated Verilog. The
first version simply stored the output address in registers and sent each
sample along with its destination address through the sorter. This means that
is contained many actual comparators. It was horrible in terms of resource use,
and with large values for inputs and period, could take days to synthesize. The
second version uses a control word, stored in a RAM, with one bit for each
swapper.

The swap elements don't use any memories. Some of the delay elements use
memories, but for really small memories the synthesizer chooses to use
registers instead.

%TODO talk about big O complexity maybe. Also for the other implementations.

\chapter{Clos Network}

\section{Theory}

The basic switching element in telephony is the crossbar switch. It can connect
its inputs with its outputs in any configuration. The electrical conductors are
arranged in a grid, where the lines in one direction are the inputs and the
other one are outputs. At each intersection, an individually controllable
switch can connect that input with that output. The crossbar switch has a
complexity of $\mathcal{O}(n^2)$ where n in the number of inputs or outputs
assuming they are the same.

\begin{figure}
\begin{center}
\includegraphics[width=.4\textwidth]{clos.eps}
\end{center}
\caption{
A Clos network with $m = n = r = 3$.
}
\label{fig:clos}
\end{figure}

A Clos network is a three stage switching network performing the same function
as a crossbar switch but using fewer resources. Depending on its parameters, it
can be capable of connecting any inputs to any outputs with varying difficulty.
It is constructed from smaller crossbar switches. In the input and output
stages, there are $r$ crossbar switches, each with $m$ connections on the side
facing the middle stage and $n$ connections on the other side. The middle stage
consists of $m$ $r \times r$ switches. Each middle switch has exactly one
connection to each of the first stage and last stage switches.  Figure
\ref{fig:clos} shows a Clos network with all parameters equal to 3.

Charles Clos proved that when $m \geq 2n - 1$ there will always be a free path
through a middle switch to make any connection immediately. Such networks are
called strictly nonblocking. If $n = m$, the network is rearrangably
nonblocking. Any set of connections can be realized, but to make a connection,
existing connections may need to be routed through other middle switches first.
Since this work is concerned with an application where patterns change rarely
and all at once, a rearrangably nonblocking Clos network is used.

\section{Routing}

To make a connection in a rearrangably nonblocking Clos network, see if there
is a middle switch whose connections to both the left crossbar switch of
interest and the one to the right is free. If the answer is yes, the connection
is trivially routed through that switch. This will always be the case if the
network is strictly nonblocking. If the answer is no, then find one middle
switch with a free connection th the left stage crossbar, and one with a free
connection to the right one. This is always possible if $m \geq n$. Now, the
task is to rearrange the connections between these two switches such that all
of them can be made.

Disconnect everything through these two middle switches and remember the set of
connections that were disconnected and the one that we want to make. Choose any
connection. Connect it through any one of the two middle switches. Find the
other connection that goes through the same right crossbar. There are always
two or less since there are two middle switches and each outer stage switch has
exactly one connection to each middle switch. Route that through the other
middle switch. Now, find the other connection through the same left crossbar
switch as the last connection and route that through the first middle switch
again. This process is repeated. Every time you go to the right, make the
connection to one middle switch and every time you go left, the other.

The connections may form several disjoint cycles or sequences, so this process
shall be repeated until all connections have been made.

\section{Space-Time-Space switch}

Consider the case where $m$ equals the number of parallel inputs to the
interleaver and $r$ equals the number of clock cycles in a period. During the
first clock cycle, all of the inputs the the first crossbar switch arrive at
the input wires. The crossbar switch would output one value to each of the
middle switches. During the next clock cycle, the inputs to the next crossbar
switch would arrive, and again it would send one sample to each of the middle
switches. It is apparent that all that is needed is one crossbar switch at the
input, which performs a different permutation each clock cycle. The same goes
for the output. The middle switches receive one sample per clock cycle and
output one sample per clock cycle to the output stage. They are easily
constructed using simple RAM memories that are written to sequentially and read
in a random order. This approach is also decribed in
\cite{DBLP:conf/icassp/PrescherGN05}.

\section{Arbitrary Size Benes Networks}

\begin{wrapfigure}{R}{.4\textwidth}
\begin{center}
\includegraphics[width=.4\textwidth]{benes.eps}
\end{center}
\caption{
How a Benes network is constructed.
}
\label{fig:benes}
\end{wrapfigure}

The input and output crossbar switches can be simplified further by using a
Benes network. It is essentially a recursive Clos network where only $2 \times
2$ switches are used. Benes networks can only be constructed when the number of
inputs is a power of two but this limitation can be overcome.

The paper Arbitrary Size Benes Networks\cite{Chang97arbitrarysize} describes
an approach to creating Benes networks with any number of inputs. When turning
a crossbar switch with an even number of inputs to a Benes network, two middle
switches, each with half that many inputs, are created. Every pair of two
inputs and outputs are given one $2 \times 2$ switch, with one connection to
each middle switch. The two middle switches are then turned into a Benes
network recursively. This is the same as a regular Benes network. One step of
this process is shown in \figureref{fig:benes}.

\begin{wrapfigure}{R}{.4\textwidth}
\begin{center}
\includegraphics[width=.4\textwidth]{asbenes.eps}
\end{center}
\caption{
One step in the construction of an Arbitrary Size Benes Network.
}
\label{fig:asbenes}
\end{wrapfigure}

The difference comes when turning a network with an odd number of inputs into a
clos network. The bottom middle switch is made one input larger than the top
one, and the extraneous input is connected directly to the bottom switch.
\Figureref{fig:asbenes} shows this.

The process of routing a Benes network amounts to the same as routing any
rearrangably nonblocking Clos network, but done recursively in the same manner
that the network is constructed. Routing an arbitrarily sized benes network is
the same except that a connection which goes through the last input -- the one
without a $2 \times 2$ switch -- obviously cannot go through the upper middle
switch but must go through the lower one instead. Any cycle or sequence which
includes this connection must be routed so that this is possible.

\section{Implementation}

The interleaver was implemented as described. Two arbitraril-size benes
networks are constructed. One at the input and one at the output. They are
pipelined, so that they will not limit the maximum clock frequency no matter
their size. In pipelining them, delay elements must be inserted in paths that
do not have crossbar switches were other paths do. Each $2 \times 2$ switch is
controlled by one bit in the control word. The control word is individually set
for each clock cycle in a period and is stored in a memory.

The middle switches were implemented from two single port memories each. When
one is being written to, the other one is being read. When the first one is
full, they switch. A delay of one frame is caused by this. The read address for
each TSI is part of the control word.

Routing is done in the \lstinline[language=C]{generate_pattern_data()}
function. The delay of each stage as a result of pipelining and the memories is
compensated for by delaying the control bits for later stages by the right
number of clock cycles.

A previous version of the Clos network based interleaver used a shift register
for its pattern, but this used up a lot of resources.

An attempt to write this interleaver without using code generation was done.
The ports were generated but everything else was done using for loops,
functions and tasks.

Functions in Verilog 2001 do not have automatic arguments. They are essentially
global variables. Benes networks are recursive, but a way to implement these
without using recursion was found. The implementation did run in the simulator,
but the synthesizer refused to synthesize it seemingly because it was unable to
recognize that some function calls were in fact constant.

The attempt was abandoned and the Clos interleaver was implemented like all the
other ones.

\chapter{Results}

\section{Testing}

All interleavers were tested in the testbench with a few different values for
inputs and period until I was satisfied that they probably worked.

A script was written to generate and then synthesize each type of interleaver
with varying combinations of inputs and period. The interleavers were
synthesized for a very large \abbrFPGA that was not actually used, so that they
would fit fur sure. The output of each synthesizer run was saved in a log file
but the results were discarded. From the log, several parameters were extracted
using another script: the maximum clock frequency, the amount of \abbrFPGA
logic resources used measured in LUT-Flip Flop pairs, the amount of RAM used
measured in bits and the time the synthesis took in seconds.

The \abbrFPGA has built-in memory modules. It does not report its resource use
in area like an ASIC design tool might. Instead, it gives the RAM usage numbers
and the logic slice usage separately. Design Compiler was available was able to
synthesize the designs. A memory compiler was not available, however. Without a
memory compiler, registers and combinatorial logic would be used for the
memories, and it was felt that this would not give an accurate representation
of the resource use in a real implemetation, so Design Compiler was ignored.

The parameters chosen were the following: The bit width of the samples was 4.
The number of inputs varied. All powers of two from 2 to 32 were used. Powers
of two from 4 to 2048 were used for the period. All combinations of these
parameters were tested giving 50 different version of each interleaver.

The first attempt was made on the initial versions of the interleavers which
used shift registers for the pattern or, in the case of the bitonic sorter,
comparators. It ran for a week on several different computers and had by that
time only done some of the smaller configurations. The choice was made to use
memories for storing the pattern instead. The shift register versions were not
tested further, but they remain in the program.

When the interleavers had been reimplemented using memories, the synthesis was
run again. This time it finished overnight on one computer. Parallel memories
with inputs set to 32 still wouldn't synthesize, which is why they are absent
from the data.

\section{Results}

The result of the synthesis runs are shown in figures \Hypref{fig:inputsmhz},
\Hypref{fig:periodmhz}, \Hypref{fig:inputspairs}, \Hypref{fig:periodpairs},
\Hypref{fig:inputsbits} and \Hypref{fig:periodbits}. The clock frequency, logic
complexity and memory sizes are plotted. Two cross-sections of each dataset are
shown. One where inputs is 8 and period varies and one where period is 512 and
the number of inputs varies.

Figure \ref{fig:inputsmhz} shows the clock freqency as inputs varies. The clock
frequency for Clos network and Bitonic sorter are not strongly affected by the
number of inputs, but the clock frequency of the Parallel memories decreases as
inputs increases. This is probably because of the large multiplexers at the
input, which are not pipelined.

Clock frequency as a function of period is shown in \figureref{fig:periodmhz}.
Bitonic sorter is mostly constant while the other two decrease. The
combinatorial part of the Clos network is almost completely unchanged as the
period increases, so this result must be because larger memories have a greater
latency. This would explain why Bitonic doesn't decrease as much. It uses a
larger number of smaller memories. In both these graphs, however, the Clos
network is the best regardless of parameters. This is a recurring pattern.

In \figureref{fig:inputspairs} the complexity of the logic as a function of
inputs is shown. It seems to be linear for Clos and Bitonic and quadratic for
Parallel memories. This would make sense as the number of memories and
multiplexers is the square of the number of inputs in that implementation.
Again, Clos is the best everywhere.

Logic complexity of the Parallel memories and Clos network should not be
dependent on period length. \Figureref{fig:periodpairs} shows that, for the
Clos network, it is not. The complexity of the Parallel memories does vary with
period, but actually goes down for the largest period, so this result may not
mean anything. Complexity of the Bitonic sorter goes up, since a longer period
means more stages.

The memory use of the parallel memories is quadratic with respect to the number
of inputs (shown in \figureref{fig:inputsbits}). The data memories should be
linear, so this probably means that the pattern memories dominate. There is
nothing more of interest here. The Clos network does the best as usual.

\begin{figure}
\begin{center}
\begin{tikzpicture}
	\begin{axis}[
		xlabel=Inputs,
		ylabel=MHz,
		legend pos=outer north east,
		cycle list name=black white
]
		\addplot table [
			x=Inputs,
			y=MHz,
			col sep=comma,
			discard if not={Type}{4}
		] {InputsMHz.csv};
		\addlegendentry{Parallel Memories}
		\addplot table [
			x=Inputs,
			y=MHz,
			col sep=comma,
			discard if not={Type}{5}
		] {InputsMHz.csv};
		\addlegendentry{Clos Network}
		\addplot table [
			x=Inputs,
			y=MHz,
			col sep=comma,
			discard if not={Type}{6}
		] {InputsMHz.csv};
		\addlegendentry{Bitonic Sorter}
	\end{axis}
\end{tikzpicture}
\end{center}
\caption{
The limit on clock frequency of the different designs depending on the number
of parallel inputs. The period is 512. Higher is better.
}
\label{fig:inputsmhz}
\end{figure}

\begin{figure}
\begin{center}
\begin{tikzpicture}
	\begin{axis}[
		xlabel=Period,
		ylabel=MHz,
		legend pos=outer north east,
		cycle list name=black white
]
		\addplot table [
			x=Period,
			y=MHz,
			col sep=comma,
			discard if not={Type}{4}
		] {PeriodMHz.csv};
		\addlegendentry{Parallel Memories}
		\addplot table [
			x=Period,
			y=MHz,
			col sep=comma,
			discard if not={Type}{5}
		] {PeriodMHz.csv};
		\addlegendentry{Clos Network}
		\addplot table [
			x=Period,
			y=MHz,
			col sep=comma,
			discard if not={Type}{6}
		] {PeriodMHz.csv};
		\addlegendentry{Bitonic Sorter}
	\end{axis}
\end{tikzpicture}
\end{center}
\caption{
Clock frequency depending on the period length. Inputs are fixed at 8.
}
\label{fig:periodmhz}
\end{figure}

\begin{figure}
\begin{center}
\begin{tikzpicture}
	\begin{axis}[
		xlabel=Inputs,
		ylabel=LUT Flip-Flop Pairs,
		legend pos=outer north east,
		cycle list name=black white
]
		\addplot table [
			x=Inputs,
			y=LUT_ff_pairs,
			col sep=comma,
			discard if not={Type}{4}
		] {InputsPairs.csv};
		\addlegendentry{Parallel Memories}
		\addplot table [
			x=Inputs,
			y=LUT_ff_pairs,
			col sep=comma,
			discard if not={Type}{5}
		] {InputsPairs.csv};
		\addlegendentry{Clos Network}
		\addplot table [
			x=Inputs,
			y=LUT_ff_pairs,
			col sep=comma,
			discard if not={Type}{6}
		] {InputsPairs.csv};
		\addlegendentry{Bitonic Sorter}
	\end{axis}
\end{tikzpicture}
\end{center}
\caption{
Logic complexity by inputs when period is 512. Lower is better.
}
\label{fig:inputspairs}
\end{figure}

\begin{figure}
\begin{center}
\begin{tikzpicture}
	\begin{axis}[
		xlabel=Period,
		ylabel=LUT Flip-Flop Pairs,
		legend pos=outer north east,
		cycle list name=black white
]
		\addplot table [
			x=Period,
			y=LUT_ff_pairs,
			col sep=comma,
			discard if not={Type}{4}
		] {PeriodPairs.csv};
		\addlegendentry{Parallel Memories}
		\addplot table [
			x=Period,
			y=LUT_ff_pairs,
			col sep=comma,
			discard if not={Type}{5}
		] {PeriodPairs.csv};
		\addlegendentry{Clos Network}
		\addplot table [
			x=Period,
			y=LUT_ff_pairs,
			col sep=comma,
			discard if not={Type}{6}
		] {PeriodPairs.csv};
		\addlegendentry{Bitonic Sorter}
	\end{axis}
\end{tikzpicture}
\end{center}
\caption{
Logic complexity by period when inputs is 8.
}
\label{fig:periodpairs}
\end{figure}

\begin{figure}
\begin{center}
\begin{tikzpicture}
	\begin{axis}[
		xlabel=Inputs,
		ylabel=RAM Bits,
		legend pos=outer north east,
		cycle list name=black white
]
		\addplot table [
			x=Inputs,
			y=RAM_Bits,
			col sep=comma,
			discard if not={Type}{4}
		] {InputsBits.csv};
		\addlegendentry{Parallel Memories}
		\addplot table [
			x=Inputs,
			y=RAM_Bits,
			col sep=comma,
			discard if not={Type}{5}
		] {InputsBits.csv};
		\addlegendentry{Clos Network}
		\addplot table [
			x=Inputs,
			y=RAM_Bits,
			col sep=comma,
			discard if not={Type}{6}
		] {InputsBits.csv};
		\addlegendentry{Bitonic Sorter}
	\end{axis}
\end{tikzpicture}
\end{center}
\caption{
Memory use by inputs when period is 512.
}
\label{fig:inputsbits}
\end{figure}

\begin{figure}
\begin{center}
\begin{tikzpicture}
	\begin{axis}[
		xlabel=Period,
		ylabel=RAM Bits,
		legend pos=outer north east,
		cycle list name=black white
]
		\addplot table [
			x=Period,
			y=RAM_Bits,
			col sep=comma,
			discard if not={Type}{4}
		] {PeriodBits.csv};
		\addlegendentry{Parallel Memories}
		\addplot table [
			x=Period,
			y=RAM_Bits,
			col sep=comma,
			discard if not={Type}{5}
		] {PeriodBits.csv};
		\addlegendentry{Clos Network}
		\addplot table [
			x=Period,
			y=RAM_Bits,
			col sep=comma,
			discard if not={Type}{6}
		] {PeriodBits.csv};
		\addlegendentry{Bitonic Sorter}
	\end{axis}
\end{tikzpicture}
\end{center}
\caption{
Memory use by period when inputs is 8.
}
\label{fig:periodbits}
\end{figure}

%TODO: perhaps also want information on the application (what size FFTs and
%which inputs/period is ideal?).

\chapter{Discussion}

\section{Results}

It's clear from the graphs that the Clos network is the best solution to the
problem. The differences can be significant depending on what the parameters
are. It's interesting to note how much better the clos network is than the
Bitonic sorter despite the fact that they both are implemented using only
single port RAMs and 2x2 swappers. A Benes network uses $\mathcal{O}(N
log_2{N})$ switches and a Bitonic sorter uses $\mathcal{O}(N log_2^2 N)$, where
$N$ is the number of inputs, yet both can perform any permutation. The
difference probably comes from the extra information available to the Benes
network. The Bitonic sorter is not the most efficient sorter, however. The
existence of simple $\mathcal{O}(N log_2 N)$ sorting networks is an open
question.

Another very clear result is that it was a terrible idea to use shift
registers. Learn from my mistakes and use memories.

\section{Future Work}

The Bitonic sorter is currently limited to power-of-two parameters. It should
be possible to construct a sorter for the next larger power of two and then
simply ignore any swap that touches wires that are not used. Perhaps there are
other problems with this approach, but it should be considered.

It is possible that the use of a "full" signal instead of a "ready" signal
would simplify the hardware considerably, removing the need for a buffer on the
output. The current handshaking scheme was chosen because I couldn't find any
information on this on the internet and it seemed like a good choice at the
time.

There are some variations on the Clos network that could be considered. A Benes
network happens to be equivalent to two butterfly network opposite one another.
Omega networks are equivalent to butterfly networks. Perhaps two Omega networks
opposite one another would do the same thing and have some interesting
properties.
%(TODO can cite equivalence if it matters (A Systematic Analysis of Equivalence
%in Multi-Stage Networks))
Another thing that could be tried is to create a big Benes network and then
serialize it in a similar way to the Bitonic sorter, instead of using RAMs for
the middle stage as currently. My humble prediction is that neither approach
will give better results than the STS switch, though.

There is a sorting network with $\mathcal{O}(N log_2 N)$ complexity and a
reasonably simple implementation called the Zig-Zag sorter. Its latency is $n
log_2 N$ but this would not be a problem for our application. It may be worth
investigating.

It's possible to extend the Parallel memories and STS interleavers so that they
support variable patterns lengths (with a maximum of the one that was
specified). This might be interesting in some applications. For it to be
useful, more control over when a new pattern is selected would almost certainly
be required.

An STS network using multiplexers instead of the Benes switches at the input
and output may be better when the number of inputs is very small and the
interleaver is implemented on an \abbrFPGA because most of them have very
efficient multiplexers.

STSs switches are not common in telephone systems. TST switches are used
instead, at least if the literature is to be believed. A TST switch has
memories on the input and output and a crossbar switch (possibly Benes) in the
middle. This is probably because the crossbar switch is more expensive than the
memories, which would be the case when the number of inputs is larger (by some
factor) than the period. The intended application has a much longer period than
number of inputs, so the choice of STS over TST is the right one. Still, TST
switches could be investigated.

In the STS switch, the benes switches have one pipeline step for each 2x2
switch. This is good for clock frequency, but may be bad for area utilization
and power use. An implementation without any pipelining or with registers only
every $n$th step might be better, especially if clock frequency is limited
elsewhere.

It may be worth looking at implementations with different numbers of outputs
and inputs.

\bibliography{IEEEfull,bib}

\end{document}
